FROM python:3.10-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
    openjdk-17-jre-headless \
    wget \
    curl \
    netcat-openbsd \
    ca-certificates \
    gnupg \
    bash \
    tar \
    procps \
    && rm -rf /var/lib/apt/lists/*

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

ENV HADOOP_VERSION=3.3.6
RUN wget https://downloads.apache.org/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz && \
    tar -xzf hadoop-${HADOOP_VERSION}.tar.gz && \
    mv hadoop-${HADOOP_VERSION} /opt/hadoop && \
    rm hadoop-${HADOOP_VERSION}.tar.gz

ENV HADOOP_HOME=/opt/hadoop
ENV PATH=$HADOOP_HOME/bin:$PATH

RUN pip install --no-cache-dir \
    pyhive \
    pyhive[thrift] \
    thrift \
    thrift_sasl \
    luigi[hadoop,mysql] \
    kafka-python \
    'sqlalchemy<2.0' \
    python-dotenv \
    hdfs  # Instalar el cliente HDFS para Python

RUN mkdir -p /opt/luigi/logs /opt/luigi/state

WORKDIR /opt/luigi
COPY ./luigi /opt/luigi

COPY .env /opt/luigi/.env

COPY ./hadoop_config/core-site.xml /opt/hadoop/etc/hadoop/core-site.xml
COPY ./hadoop_config/hdfs-site.xml /opt/hadoop/etc/hadoop/hdfs-site.xml
COPY ./hadoop_config/mapred-site.xml /opt/hadoop/etc/hadoop/mapred-site.xml
COPY ./hadoop_config/yarn-site.xml /opt/hadoop/etc/hadoop/yarn-site.xml

CMD ["luigid"]
